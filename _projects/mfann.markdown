---

[comment]: # Do not change the layout
layout: project

[comment]: # Project title
title: "MFANN"

[comment]: # The image should be added to images/projects/
image: "mfann.png"

[comment]: # List of project members.
people: ["Daniel Grzenda", "Kyle Chard", "Ian Foster"]

[comment]: # List of project tags. Remove all that do not apply
hashtags: [
    "Functional Approximation", "Neural Networks", "Machine Learning", "Artificial Intelligence"
]

[comment]: # GitHub link or blank if not applicable
github: "https://github.com/danielgrzenda/mfann/tree/main"

[comment]: # Website/homepage/docs or blank if not applicable
website: ""  

[comment]: # One-line teaser/description for front page/project page
teaser: "Mutivariate Functional Approximation through Neural Networks"

[comment]: # Set to false if the project is no longer maintained
active: true

---

<!-- website: "https://danielgrzenda.com/projects/mfann" -->

We developed the Multivariate Functional Approximation Neural Network (MFANN), an architecture that combines the principles of multivariate functional approximation (MFA) 
with iterative optimization techniques commonly found in the neural network (NN) literature. MFA is a data modeling, compression, and visualization tool that uses the tensor product 
of B-spline functions to build continuous, differentiable representations of input data. We extend MFA to use stochastic iterative mini-batch optimization methods, 
periodically updating the spline-based models instead of numerically solving for the representation. We've demonstrated MFANN is less prone to common problems in neural network optimization, 
such as overfitting and hyperparameter selection, while remaining flexible enough to fit complex analytical functions and real-world scientific data. Our work highlights MFANN as 
a promising paradigm for advancing the theory and practice of data-driven function approximation with a new class of neural networks.

#### Publications
<!-- List the full citations for each paper here with links to where to find it. -->

Coming soon!

<!-- - Maxime Gonthier, Dante D. Sanchez-Gallegos, Haochen Pan, Bogdan Nicolae, Sicheng Zhou, Hai Duc Nguyen, Valerie Hayot-Sasson, Greg Pauloski, Jesus Carretero, Kyle Chard, Ian Foster. 2025. [D-Rex: Heterogeneity-Aware Reliability Framework and Adaptive Algorithms for Distributed Storage](https://hpcrl.github.io/ICS2025-webpage/program/Proceedings_ICS25/ics25-52.pdf). In Proceedings of the ACM International Conference on Supercomputing (ICS 25). -->

#### Funding and Acknowledgements
<!-- List any funding sources or other acknowledgements here otherwise remove -->
This work is partially funded by the NSF CSGrad4US Fellowship.
